{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskAllButNPixels(object):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Ensure img is a tensor and squeeze it\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            img = transforms.ToTensor()(img)\n",
    "        img = img.squeeze()\n",
    "        \n",
    "        mask = torch.zeros_like(img)\n",
    "        new_img = torch.zeros_like(img)\n",
    "        \n",
    "        non_zero_indices = torch.nonzero(img)\n",
    "        if len(non_zero_indices) < self.N:\n",
    "            return torch.stack([mask, img])\n",
    "        \n",
    "        random_indices = torch.randperm(len(non_zero_indices))[:self.N]\n",
    "        rows, cols = non_zero_indices[random_indices].T\n",
    "        \n",
    "        mask[rows, cols] = 1\n",
    "        new_img[rows, cols] = img[rows, cols]\n",
    "        \n",
    "        return torch.stack([mask, new_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MaskAllButNPixels and visualize results for multiple scenarios\n",
    "transform = MaskAllButNPixels(num_unmasked_pixels)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "\n",
    "# Test scenarios\n",
    "scenarios = [\n",
    "    (\"Random digit\", random.randint(0, len(mnist_data) - 1)),\n",
    "    (\"Digit with few non-zero pixels\", mnist_data.targets.tolist().index(1)),  # '1' typically has fewer pixels\n",
    "    (\"Digit with many non-zero pixels\", mnist_data.targets.tolist().index(8))  # '8' typically has more pixels\n",
    "]\n",
    "\n",
    "for scenario_name, sample_idx in scenarios:\n",
    "    sample_image, label = mnist_data[sample_idx]\n",
    "\n",
    "    # Apply the transformation\n",
    "    transformed_image = transform(sample_image)\n",
    "\n",
    "    # Visualize the original, mask, and masked image\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axes[0].imshow(sample_image, cmap='gray')\n",
    "    axes[0].set_title(f'Original Image (Digit: {label})')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(transformed_image[0].squeeze(), cmap='gray')\n",
    "    axes[1].set_title('Mask')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(transformed_image[1].squeeze(), cmap='gray')\n",
    "    axes[2].set_title(f'Masked Image ({num_unmasked_pixels} pixels)')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Scenario: {scenario_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print the number of non-zero pixels in the masked image\n",
    "    print(f\"Scenario: {scenario_name}\")\n",
    "    print(f\"Number of non-zero pixels in masked image: {torch.count_nonzero(transformed_image[1])}\")\n",
    "    print(f\"Total non-zero pixels in original image: {torch.count_nonzero(transforms.ToTensor()(sample_image))}\")\n",
    "    print()\n",
    "\n",
    "# Test edge case: image with fewer non-zero pixels than num_unmasked_pixels\n",
    "edge_case_image = torch.zeros((28, 28))\n",
    "edge_case_image[14, 14] = 1  # Single pixel in the center\n",
    "edge_case_transformed = transform(transforms.ToPILImage()(edge_case_image))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(edge_case_image, cmap='gray')\n",
    "axes[0].set_title('Edge Case: Single Pixel Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(edge_case_transformed[0].squeeze(), cmap='gray')\n",
    "axes[1].set_title('Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(edge_case_transformed[1].squeeze(), cmap='gray')\n",
    "axes[2].set_title(f'Masked Image ({num_unmasked_pixels} pixels)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(\"Edge Case: Fewer non-zero pixels than num_unmasked_pixels\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Edge Case: Single Pixel Image\")\n",
    "print(f\"Number of non-zero pixels in masked image: {torch.count_nonzero(edge_case_transformed[1])}\")\n",
    "print(f\"Total non-zero pixels in original image: {torch.count_nonzero(edge_case_image)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\n",
    "Concretely, the judge is trained to classify MNIST from 6 (resp. 4) nonzero pixels, with the pixels\n",
    "chosen at random at training time. The judge receives two input feature planes:\n",
    "1. A {0, 1} mask of which pixels were revealed\n",
    "2. The value of the revealed pixels (with zeros elsewhere)\n",
    "\n",
    "We used the architecture from the TensorFlow MNIST layers tutorial;\n",
    "the only difference is the input. We train the judges using:\n",
    "- Optimizer: Adam\n",
    "- Learning rate: 10^-4\n",
    "- Batches: 30k (resp. 50k)\n",
    "- Batch size: 128 samples\n",
    "\n",
    "Accuracy achieved:\n",
    "- 6 pixels: 59.4%\n",
    "- 4 pixels: 48.2%\n",
    "\"\n",
    "\n",
    "https://web.archive.org/web/20180516102820/https://www.tensorflow.org/tutorials/layers#building_the_cnn_mnist_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 1024)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x)) # 1. Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2) # 2. Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    "        x = torch.relu(self.conv2(x)) # 3. Convolutional Layer #2: Applies 64 5x5 filters, with ReLU activation function\n",
    "        x = nn.functional.max_pool2d(x, kernel_size=2, stride=2) # 4. Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x)) # 5. Dense Layer #1: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x) # 6. Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0â€“9).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 128\n",
    "num_epochs = 64 # 60,000 samples / 128 ~ 469 batches per epoch * 64 epocs = 30,016\n",
    "\n",
    "# Set number of pixels\n",
    "num_pixels = 6  # Change to 4 for the 4-pixel version\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    MaskAllButNPixels(num_pixels)\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_batches = len(train_loader)\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print statistics every epoch\n",
    "    elapsed_time = time.time() - start_time\n",
    "    estimated_total_time = elapsed_time * num_epochs / (epoch + 1)\n",
    "    remaining_time = estimated_total_time - elapsed_time\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / total_batches:.3f}')\n",
    "    print(f'Estimated time remaining: {remaining_time/60:.2f} minutes')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), f'mnist_judge_{num_pixels}pixels.pth')\n",
    "print(f'Model saved as mnist_judge_{num_pixels}pixels.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create error matrix\n",
    "error_matrix = torch.zeros(10, 10)\n",
    "total_per_class = torch.zeros(10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "            if t != p:  # Only count errors\n",
    "                error_matrix[t.long(), p.long()] += 1\n",
    "            total_per_class[t.long()] += 1\n",
    "\n",
    "# Convert to percentages of total inputs\n",
    "error_matrix_percent = error_matrix / len(test_dataset) * 100\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "cmap = plt.cm.jet\n",
    "cmap.set_bad('black')  # Set the color for masked values to black\n",
    "\n",
    "masked_error_matrix = np.ma.array(error_matrix_percent.numpy(), mask=np.eye(10))  # Mask diagonal\n",
    "im = plt.imshow(masked_error_matrix, cmap=cmap, vmin=0, vmax=2)\n",
    "\n",
    "# Create colorbar\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label('Percentage of total inputs', rotation=270, labelpad=15)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:  # Skip diagonal elements\n",
    "            text = plt.text(j, i, f'{error_matrix_percent[i, j]:.2f}%', \n",
    "                            ha=\"center\", va=\"center\", color=\"white\" if error_matrix_percent[i, j] < 1 else \"black\")\n",
    "\n",
    "plt.title(f'Error Matrix for {num_pixels}-pixel MNIST Judge')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
